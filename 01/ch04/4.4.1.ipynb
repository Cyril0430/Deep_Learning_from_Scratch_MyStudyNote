{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6909591",
   "metadata": {},
   "source": [
    "## 勾配法\n",
    "\n",
    "$${\n",
    "  x_{0,t+1}\n",
    "  =\n",
    "  x_{0,t} - \\left.\\eta\\frac{\\partial f}{\\partial x_0}\\right|_t\n",
    "}$$\n",
    "\n",
    "$${\n",
    "  x_{1,t+1}\n",
    "  =\n",
    "  x_{1,t} - \\left.\\eta\\frac{\\partial f}{\\partial x_1}\\right|_t\n",
    "}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb75b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x) # xと同じ要素数の空の配列を用意する（生成する）\n",
    "\n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]    # tmp_valに元の独立変数の値を保存する\n",
    "        x[idx] = tmp_val + h    # x[idx]に元の値から少し正の方向へhだけ動かしたときの値を代入\n",
    "        fxh1 = f(x) # 十分小さくxを動かした後の関数値をfxh1に代入\n",
    "\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val\n",
    "    \n",
    "    return grad\n",
    "    \n",
    "\n",
    "# 勾配降下法の実装\n",
    "\n",
    "def gradient_descent(f, init_x, lr = 0.01, step_num = 100):\n",
    "    \"\"\"勾配降下法\n",
    "\n",
    "    f: 適用する関数 \\n\n",
    "    init_x: 初期値 \\n\n",
    "    lr: 学習率（learning rate）（既定値:0.01）\\n\n",
    "    step_num: 勾配法による繰り返しの数（既定値:100）\n",
    "    \"\"\"\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d0b49",
   "metadata": {},
   "source": [
    "### 例\n",
    "${f(x_0, x_1) = x_0^2 + x_1^2}$ の最小値を勾配法で求めよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c202672a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.11110793e-10  8.14814391e-10]\n"
     ]
    }
   ],
   "source": [
    "def function_2(x):\n",
    "    return np.sum(x**2)\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])  # 初期値は点(-3.0, 4.0)\n",
    "\n",
    "print(gradient_descent(function_2, init_x = init_x, lr = 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2c9f2e",
   "metadata": {},
   "source": [
    "学習率（learning rate）は大きすぎても小さすぎてもいけないということについて、実験してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8068956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.58983747e+13 -1.29524862e+12]\n"
     ]
    }
   ],
   "source": [
    "# 学習率が大きすぎる場合（lr = 10.0）\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "\n",
    "print(gradient_descent(function_2, init_x = init_x, lr = 10.0, step_num = 100))  # [-2.58983747e+13 -1.29524862e+12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9068bc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.99999994  3.99999992]\n"
     ]
    }
   ],
   "source": [
    "# 学習率が小さすぎる場合（lr = 1e-10）\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "\n",
    "print(gradient_descent(function_2, init_x = init_x, lr = 1e-10, step_num = 100))    # [-2.99999994  3.99999992]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da142e1b",
   "metadata": {},
   "source": [
    "要するに、学習率が大きすぎると更新しすぎる（大きな値へと「発散」する）。逆に学習率が小さすぎるとほとんど更新されない。\n",
    "\n",
    "学習率のようなパラメータを**ハイパーパラメータ**と言う。ニューラルネットワークのパラメータ（重みやバイアス）は学習によって自動的に決まるのに対し、ハイパーパラメータは人間が手動で設定される必要がある。\n",
    "\n",
    "ハイパーパラメータは人間が試行錯誤し、うまく学習できるケースを探すという作業が必要になる。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
